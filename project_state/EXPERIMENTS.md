# Experiments

| Name | Entry Point | Purpose | Key Inputs / Flags | Metrics & Outputs | Default Output Paths |
| --- | --- | --- | --- | --- | --- |
| Tri-Engine Agreement | `python scripts/tri_engine_agreement.py --quant-cli build/quant_cli --output ... --csv ...` | Cross-check analytic BS vs MC vs PDE across strikes; ensure ≤5 bps gap | Market params (hard-coded), optional cli path | Price curves; CSV of BS/MC/PDE values | `docs/artifacts/tri_engine_agreement.{csv,png}` |
| QMC vs PRNG (equal wall-clock) | `python scripts/qmc_vs_prng_equal_time.py --output ... --csv ... [--fast]` | Compare Sobol+BB vs PRNG RMSE at matched wall-clock for Euro/Asian | MC steps, seeds, runtime grid (script fixed), `--fast` trims reps | RMSE vs seconds; RMSE ratio | `docs/artifacts/qmc_vs_prng_equal_time.{csv,png}` |
| MC Greeks CI | `python scripts/mc_greeks_ci.py --quant-cli build/quant_cli --output ... --csv ...` | Validate MC Δ/ν/Γ/Θ estimators vs analytic with 95% CI | Paths, steps, seeds (script defaults) | Estimator mean/SE/CI per Greek | `docs/artifacts/mc_greeks_ci.{csv,png}` |
| Heston QE vs Analytic | `python scripts/heston_qe_vs_analytic.py --quant-cli build/quant_cli --output ... --csv ... [--fast]` | Bias/RMSE study of Andersen QE & Euler vs analytic CF across parameter grids (base/stress/Feller) | Path/step grids, scenario definitions, optional `--fast` | Price & IV RMSE, bias per grid | `docs/artifacts/heston_qe_vs_analytic.{csv,png}` |
| PDE Order / Walltime | `python scripts/pde_order_slope.py --skip-build --output ... --csv ...` | Convergence slope of CN (Δ/Γ/price) vs grid size | Grid refinements preset; optional skip-build | Fitted slope, RMSE columns | `docs/artifacts/pde_order_slope.{csv,png}` |
| QuantLib Parity | `python scripts/ql_parity.py --output ... --csv ...` | Compare quant_cli prices vs QuantLib (vanilla/barrier/American) | Uses QuantLib Python; reads no data | Price gaps (cents) & runtime deltas | `docs/artifacts/ql_parity/ql_parity.{csv,png}` |
| WRDS Pipeline (sample or live) | `python -m wrds_pipeline.pipeline --dateset wrds_pipeline_dates_panel.yaml [--use-sample] [--fast] [--output-root …]` | Ingest OptionMetrics, calibrate Heston & BS baseline, compute OOS IV/price MAE and Δ‑hedged PnL | WRDS env or bundled sample; dateset YAML | `wrds_agg_pricing*.csv`, `wrds_agg_oos*.csv`, `wrds_agg_pnl.csv`, insample/OOS/hedge plots, comparison heatmaps | `docs/artifacts/wrds/` (aggregates) & `docs/artifacts/wrds/per_date/<date>/` |
| Heston Calibration (normalized CSV) | `python scripts/calibrate_heston.py --input data/normalized/... [--fast] [--metric price|vol]` | Calibrate Heston to provided normalized surface | CSV schema in `scripts/data/schema.md`; optional retries/seed | params JSON, fit CSV, IV/price error plot | `artifacts/heston/params_<date>.json`, `fit_<date>.{csv,png}` |
| MC/Barrier/Greeks diagnostics | `python scripts/greeks_variance.py`, `greeks_reliability.py`, `american_consistency.py`, `parity_checks.py`, `heston_series_plot.py`, `risk_backtest.py` | Smaller focused checks (variance reduction impact, American cross-method consistency, parity, Heston term structure, risk backtest) | Embedded params; some read sample data | Printed stats + optional PNG/CSV (where applicable) | Under `docs/artifacts/` when plotting |
| Benchmarks | `./build/bench_mc`, `./build/bench_pde`, then `python scripts/generate_bench_artifacts.py ...` | Google Benchmark runs for MC throughput, equal-time RMSE, PDE walltime/order, PSOR iterations | Google Benchmark JSON from executables | CSV/PNG summarizing speed & scaling | `docs/artifacts/bench/bench_*.{json,csv,png}` |
| Package Validation | `python scripts/package_validation.py --artifacts docs/artifacts --output docs/validation_pack.zip` | Bundle committed artifacts for release reproducibility | Existing artifacts | Zip bundle | `docs/validation_pack.zip` |

Most scripts append entries to `docs/artifacts/manifest.json` via `manifest_utils.update_run`, capturing git SHA, compiler flags, seeds, and hardware.
